---
title: "Getting Started with tidylearn"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with tidylearn}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

## Introduction

`tidylearn` is a comprehensive machine learning package for R that unifies supervised and unsupervised learning under a consistent, tidy interface. Unlike packages that simply combine functionalities, tidylearn enables seamless integration between different learning paradigms.

## Installation

```{r, eval = FALSE}
# Install from GitHub
# devtools::install_github("ces0491/tidylearn")

# Or install from source
devtools::install_local("path/to/tidylearn")
```

```{r setup}
library(tidylearn)
library(dplyr)
```

## The Unified Interface

The core of tidylearn is the `tl_model()` function, which works with both supervised and unsupervised methods.

### Supervised Learning

#### Classification

```{r}
# Classification with logistic regression
model_logistic <- tl_model(iris, Species ~ ., method = "logistic")
print(model_logistic)
```

```{r}
# Make predictions
predictions <- predict(model_logistic)
head(predictions)
```

#### Regression

```{r}
# Regression with linear model
model_linear <- tl_model(mtcars, mpg ~ wt + hp, method = "linear")
print(model_linear)
```

```{r}
# Predictions
predictions_reg <- predict(model_linear)
head(predictions_reg)
```

### Unsupervised Learning

#### Dimensionality Reduction

```{r}
# Principal Component Analysis
model_pca <- tl_model(iris[, 1:4], method = "pca")
print(model_pca)
```

```{r}
# Transform data
transformed <- predict(model_pca)
head(transformed)
```

#### Clustering

```{r}
# K-means clustering
model_kmeans <- tl_model(iris[, 1:4], method = "kmeans", k = 3)
print(model_kmeans)
```

```{r}
# Get cluster assignments
clusters <- model_kmeans$fit$clusters
head(clusters)
```

```{r}
# Compare with actual species
table(clusters$cluster, iris$Species)
```

## Data Preprocessing

tidylearn provides comprehensive preprocessing functions:

```{r}
# Prepare data with multiple preprocessing steps
processed <- tl_prepare_data(
  iris,
  Species ~ .,
  impute_method = "mean",
  scale_method = "standardize",
  encode_categorical = FALSE
)
```

```{r}
# Check preprocessing steps applied
names(processed$preprocessing_steps)
```

```{r}
# Use processed data for modeling
model_processed <- tl_model(processed$data, Species ~ ., method = "forest")
```

## Train-Test Splitting

```{r}
# Simple random split
split <- tl_split(iris, prop = 0.7, seed = 123)

# Train model
model_train <- tl_model(split$train, Species ~ ., method = "logistic")

# Test predictions
predictions_test <- predict(model_train, new_data = split$test)
head(predictions_test)
```

```{r}
# Stratified split (maintains class proportions)
split_strat <- tl_split(iris, prop = 0.7, stratify = "Species", seed = 123)

# Check proportions are maintained
prop.table(table(split_strat$train$Species))
prop.table(table(split_strat$test$Species))
prop.table(table(iris$Species))
```

## Available Methods

### Supervised Methods

**Classification & Regression:**
- `"linear"` - Linear regression
- `"polynomial"` - Polynomial regression
- `"logistic"` - Logistic regression
- `"tree"` - Decision trees
- `"forest"` - Random forests
- `"boost"` - Gradient boosting
- `"xgboost"` - XGBoost
- `"svm"` - Support vector machines
- `"nn"` - Neural networks
- `"deep"` - Deep learning

**Regularization:**
- `"ridge"` - Ridge regression
- `"lasso"` - LASSO
- `"elastic_net"` - Elastic net

### Unsupervised Methods

**Dimensionality Reduction:**
- `"pca"` - Principal Component Analysis
- `"mds"` - Multidimensional Scaling

**Clustering:**
- `"kmeans"` - K-means
- `"pam"` - K-medoids (PAM)
- `"clara"` - CLARA (for large datasets)
- `"hclust"` - Hierarchical clustering
- `"dbscan"` - Density-based clustering

## Next Steps

Now that you understand the basics, explore:

1. **Supervised Learning** - Dive deeper into classification and regression
2. **Unsupervised Learning** - Explore clustering and dimensionality reduction
3. **Integration Workflows** - Combine supervised and unsupervised learning
4. **AutoML** - Automated machine learning with `tl_auto_ml()`

## Summary

tidylearn provides:
- **Unified Interface**: One function (`tl_model()`) for all methods
- **Flexible Preprocessing**: Comprehensive data preparation tools
- **Easy Integration**: Seamlessly combine different learning paradigms
- **Tidy Output**: All results are tibbles for easy manipulation

```{r}
# Quick example combining everything
data_split <- tl_split(iris, prop = 0.7, stratify = "Species", seed = 42)
data_prep <- tl_prepare_data(data_split$train, Species ~ ., scale_method = "standardize")
model_final <- tl_model(data_prep$data, Species ~ ., method = "forest")
test_preds <- predict(model_final, new_data = data_split$test)

print(model_final)
```
